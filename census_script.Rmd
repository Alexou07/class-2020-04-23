---
title: "Working with Big Data"
author: "David Kane"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(lubridate)
library(gganimate)
library(tidyverse)
```

This month, the [CenSoc Project](https://censoc.berkeley.edu/) at Berkeley released the first version of their individual-level data sets with information on almost everyone in the 1940 U.S. Census. The data is available to us. Today's project is to work with Big Data for real. (If you want to spend more time on machine learning, go through the examples in chapter 14.)

Fill out [this form](https://censoc-download.demog.berkeley.edu/) to access the data. You should receive an e-mail with a link to a page [like this one](https://censoc-download.demog.berkeley.edu/Data/Qm958Kq901/). (Do not use that page.) Download just the censoc_dmf_v1.zip file. Unzip it and place the `censoc_dmf_v1.csv` in your project. (Do not check this in to Github. It is too big.)


## Scene 1

* Read in the data into a tibble called `raw`. Make sure to use the `col_types` argument so that you code does not produce aesthetically offensive messages. 

* Be professional. Give your R code chunks names. Use `cache=TRUE` as a code chunk option for any chunk that takes a long time to run.

* Once you have the data, take a look. There is at least one bad row. Find it and change your code so that it is not read in to `raw`.

* Consider the oldest man in the dataset. (All the observation are male.) What year was he born in?

* Calculate the average age at death by birth year. What two years have the highest average? Why? Without looking can you guess which years have the lowest average?

* Which four months have the highest number of deaths? Why? What does that suggest about the influence of global warming on mortality?

```{r sc1, cache=TRUE}
# There are several reasonable ways of dealing with zip'd data. One is to do
# things by-hand, placing the new directory someplace sensible. Another is to
# have the code start with the zipped file. This is good because the less times
# that you do anything by hand the better. But it is annoying because you have
# to design your script so that you don't repeat a step that has already
# happened. For now, I will just comment out unzip(). But, if this were updated
# each day, I would handle this programmatically.

# unzip("censoc_dmf_v1.zip")

raw <- read_csv("censoc_dmf_v1.csv",
                col_types = cols(HISTID = col_character(),
                                 byear = col_double(),
                                 bmonth = col_double(),
                                 dyear = col_double(),
                                 dmonth = col_double(),
                                 death_age = col_double(),
                                 weight = col_double())) %>% 
  filter(! bmonth == 0) 
```

```{r sc1a}
raw %>% 
  arrange(desc(death_age))
```

```{r sc1b}
raw %>% 
  group_by(byear) %>% 
  summarize(avg_death_age = mean(death_age)) %>% 
  top_n(2, avg_death_age)
```

```{r sc1c}
raw %>% 
  group_by(dmonth) %>% 
  summarize(total = n()) %>% 
  top_n(4, total)
```



## Scene 2

This data set is not easy to work with because it has no dates. It just has months and years. Create two new variables: `birth_date` and `death_date`, defined as the first day of the month, even though we don't have exact day information. Drop all the other variables except `death_age`. A smaller data set will be easier to work with. Call this new tibble `x`.

Create a plot like the one on Piazza which shows a histogram of ages at death.


```{r s2, cache=TRUE}
# Separating your data processing into different code chunks can be useful. Once
# you have read the data in once, you don't want to do it 50 more times.

# In order to get this code to wor, 

x <- raw %>% 
  mutate(death_date = ymd(paste(dyear, dmonth, "01", sep = "-"))) %>% 
  select(death_date, death_age)

# There is no need to work with 5 million rows of data until you are use sure
# you code is working. Instead, get everything working with 10,000, and then go
# back. I use the small data set until things work, then switch in x.
.
small <- x %>% 
  sample_n(10000)

z2 <- x %>% 
  group_by(death_age) %>% 
  summarize(deaths = n())
```


```{r sc2a}
sc2_p <- z2 %>% 
  ggplot(aes(x = death_age, y = deaths)) + 
    geom_col() +
    labs(x = "Age at Death",
         y = "Total Number",
         title = "Number of Deaths for Each Age",
         subtitle = "Ages at death is normalesque . . .",
         caption = "1940 US Census Mortality Data from CenSoc")

sc2_p

# ggsave("scene2.jpg", sc2_p)
```


## Scene 3

Make a [cool animation](https://davidkane9.github.io/PPBDS/C-animation.html) with this data. First step is to build an interesting static graphic, using all your favorite **ggplot** tools. Then animate it in an interesting way. See Piazza for my (broken!) example. Do something similar, or better!



## Challenge Problem

Use this data and the [d3rain package](https://github.com/daranzolin/d3rain) to create a cool animation with this data. Perhaps birth years across the top. The rain falls down to either death years or to ages at death. Or something else. Impress us! Put your animation on Rpubs and leave a link on Piazza.


